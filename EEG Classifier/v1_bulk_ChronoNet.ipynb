{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Utilities\\Anaconda3\\envs\\keras\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Keras Package\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, Flatten, LSTM, Embedding, Reshape, GRU, Input, RNN\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "#Numpy\n",
    "import numpy as np\n",
    "#Load Data\n",
    "import h5py, glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "#Timing\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "def import_data(filename):\n",
    "    #Removes nan trial from imported data\n",
    "    def remove_nan(X):\n",
    "        idx = 0\n",
    "        idx_nan = []\n",
    "        for trial in X:\n",
    "            if (np.isnan(trial).any()):\n",
    "                print('Trial %d has nan' % idx)\n",
    "                idx_nan.append(idx)\n",
    "            idx += 1\n",
    "        return np.delete(X,idx_nan,0), np.delete(y,idx_nan,0)\n",
    "\n",
    "    #Load data\n",
    "    A01T = h5py.File(filename, 'r')\n",
    "    X = np.copy(A01T['image'])\n",
    "    X = X[:,0:22,:] #remove EOG lines\n",
    "\n",
    "    #769-left hand; 770-right hand; 771-both feet; 772-tongue\n",
    "    y = np.copy(A01T['type'])\n",
    "    y = y[0,0:X.shape[0]:1]\n",
    "    y = np.asarray(y, dtype=np.int32)\n",
    "    \n",
    "    #Data Preprocess\n",
    "    X, y = remove_nan(X) #Remove nans\n",
    "    X = np.transpose(X,(0,2,1))\n",
    "    X = np.expand_dims(X,3) #Expand dimension\n",
    "\n",
    "    #Convert y to one-hot label\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    encoded_y = encoder.transform(y)\n",
    "    y = np_utils.to_categorical(encoded_y)\n",
    "    num_classes = y.shape[1]\n",
    "\n",
    "    #Check whole dimensions\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    return X, y, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Trial 56 has nan\n",
      "(287, 1000, 22, 1)\n",
      "(287, 4)\n",
      "1\n",
      "Trial 237 has nan\n",
      "Trial 284 has nan\n",
      "(286, 1000, 22, 1)\n",
      "(286, 4)\n",
      "2\n",
      "Trial 113 has nan\n",
      "Trial 249 has nan\n",
      "(286, 1000, 22, 1)\n",
      "(286, 4)\n",
      "3\n",
      "Trial 144 has nan\n",
      "Trial 145 has nan\n",
      "Trial 146 has nan\n",
      "Trial 179 has nan\n",
      "(284, 1000, 22, 1)\n",
      "(284, 4)\n",
      "4\n",
      "Trial 6 has nan\n",
      "Trial 28 has nan\n",
      "Trial 57 has nan\n",
      "Trial 101 has nan\n",
      "Trial 220 has nan\n",
      "Trial 225 has nan\n",
      "(282, 1000, 22, 1)\n",
      "(282, 4)\n",
      "5\n",
      "Trial 97 has nan\n",
      "Trial 115 has nan\n",
      "Trial 140 has nan\n",
      "(285, 1000, 22, 1)\n",
      "(285, 4)\n",
      "6\n",
      "(288, 1000, 22, 1)\n",
      "(288, 4)\n",
      "7\n",
      "Trial 58 has nan\n",
      "Trial 81 has nan\n",
      "Trial 124 has nan\n",
      "Trial 151 has nan\n",
      "Trial 178 has nan\n",
      "Trial 275 has nan\n",
      "(282, 1000, 22, 1)\n",
      "(282, 4)\n",
      "8\n",
      "Trial 22 has nan\n",
      "Trial 61 has nan\n",
      "Trial 92 has nan\n",
      "Trial 93 has nan\n",
      "Trial 159 has nan\n",
      "Trial 202 has nan\n",
      "Trial 204 has nan\n",
      "Trial 218 has nan\n",
      "Trial 239 has nan\n",
      "Trial 250 has nan\n",
      "(278, 1000, 22, 1)\n",
      "(278, 4)\n"
     ]
    }
   ],
   "source": [
    "#Load files\n",
    "files = glob.glob('project_datasets/*.mat')\n",
    "subjects = -1\n",
    "X = {}\n",
    "y = {}\n",
    "for file in files:\n",
    "    subjects += 1\n",
    "    print(subjects)\n",
    "    X[str(subjects)], y[str(subjects)], num_classes = import_data(file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Concatenate all data (for v2_bulk)\n",
    "# t0 = time()\n",
    "# X_net = X[str(0)];\n",
    "# y_net = y[str(0)];\n",
    "# for i in np.arange(1,len(X)):\n",
    "#     X_net = np.concatenate((X_net,X[str(i)]),axis=0)\n",
    "#     y_net = np.concatenate((y_net,y[str(i)]),axis=0)\n",
    "# t1 = time()\n",
    "# total = t1 - t0\n",
    "# print(\"Time to concatenate = %f\" % total)\n",
    "# print()\n",
    "\n",
    "#Creating Validation and Testing data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_net, y_net, test_size = 5/100, random_state=0)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 5/95, random_state=0)\n",
    "# print(X_net.shape)\n",
    "# print(X_train.shape)\n",
    "# print(X_val.shape)\n",
    "# print(X_test.shape)\n",
    "# print()\n",
    "# print(y_net.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_val.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1998, 1000, 22, 1)\n",
      "(282, 1000, 22, 1)\n",
      "(278, 1000, 22, 1)\n",
      "\n",
      "(1998, 4)\n",
      "(282, 4)\n",
      "(278, 4)\n"
     ]
    }
   ],
   "source": [
    "# #Concatenate all data (for v1_bulk)\n",
    "idx = np.arange(len(X))\n",
    "idx_train = idx[0:-2]\n",
    "idx_val = idx[-2]\n",
    "idx_test = idx[-1]\n",
    "X_train, y_train = X[str(idx_train[0])], y[str(idx_train[0])]\n",
    "X_val, y_val = X[str(idx_val)], y[str(idx_val)]\n",
    "X_test, y_test = X[str(idx_test)], y[str(idx_test)]\n",
    "for i in idx_train[1:]:\n",
    "    X_train = np.concatenate((X_train,X[str(i)]),axis=0)\n",
    "    y_train = np.concatenate((y_train,y[str(i)]),axis=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print()\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Deep CNN\n",
    "# Conv2D: (layer name, filter length, number of filters, stride size)\n",
    "# GRU layers: (layer name, number of filters)\n",
    "def create_rnn():\n",
    "    activation = 'elu'\n",
    "    input_shape = Input(shape = X['1'][0].shape)\n",
    "    init = 'glorot_uniform'\n",
    "\n",
    "    #Block 1\n",
    "#     cnn_1 = Conv2D(25, (10,1), kernel_initializer=init)(input_shape)\n",
    "#     cnn_1 = Conv2D(25, (1,22), kernel_initializer=init)(cnn_1)\n",
    "#     cnn_1 = BatchNormalization()(cnn_1)\n",
    "#     cnn_1 = Activation(activation)(cnn_1)\n",
    "#     cnn_1 = MaxPooling2D(pool_size=(3, 1), strides=3)(cnn_1)\n",
    "#     cnn_1 = Dropout(0.5)(cnn_1)\n",
    "    \n",
    "    #Inception 1\n",
    "    tower_11 = Conv2D(50, (5,22), strides=(5,22), padding='same', kernel_initializer=init)(input_shape)\n",
    "    tower_12 = Conv2D(50, (10,22), strides=(5,22), padding='same', kernel_initializer=init)(input_shape)\n",
    "    tower_13 = Conv2D(50, (20,22), strides=(5,22), padding='same', kernel_initializer=init)(input_shape)\n",
    "    inception_output_1 = keras.layers.concatenate([tower_11, tower_12, tower_13], axis = 3)\n",
    "    inception_output_1 = BatchNormalization()(inception_output_1)\n",
    "    inception_output_1 = Activation(activation)(inception_output_1)\n",
    "    inception_output_1 = Dropout(0.5)(inception_output_1)\n",
    "    \n",
    "    #Inception 2\n",
    "    tower_21 = Conv2D(50, (5,1), strides=5, padding='same', kernel_initializer=init)(inception_output_1)\n",
    "    tower_22 = Conv2D(50, (10,1), strides=5, padding='same', kernel_initializer=init)(inception_output_1)\n",
    "    tower_23 = Conv2D(50, (20,1), strides=5, padding='same', kernel_initializer=init)(inception_output_1)\n",
    "    inception_output_2 = keras.layers.concatenate([tower_21, tower_22, tower_23], axis = 3)\n",
    "    inception_output_2 = BatchNormalization()(inception_output_2)\n",
    "    inception_output_2 = Activation(activation)(inception_output_2)\n",
    "    inception_output_2 = Dropout(0.5)(inception_output_2)\n",
    "    \n",
    "    #Inception 3\n",
    "    tower_31 = Conv2D(50, (5,1), strides=5, padding='same', kernel_initializer=init)(inception_output_2)\n",
    "    tower_32 = Conv2D(50, (10,1), strides=5, padding='same', kernel_initializer=init)(inception_output_2)\n",
    "    tower_33 = Conv2D(50, (20,1), strides=5, padding='same', kernel_initializer=init)(inception_output_2)\n",
    "    inception_output_3 = keras.layers.concatenate([tower_31, tower_32, tower_33], axis = 3)\n",
    "    inception_output_3 = BatchNormalization()(inception_output_3)\n",
    "    inception_output_3 = Activation(activation)(inception_output_3)\n",
    "    inception_output_3 = Dropout(0.5)(inception_output_3)\n",
    "\n",
    "#     #Block 2\n",
    "#     cnn_2 = Conv2D(50, (10,1), kernel_initializer=init)(cnn_1)\n",
    "#     cnn_2 = BatchNormalization()(cnn_2)\n",
    "#     cnn_2 = Activation(activation)(cnn_2)\n",
    "#     cnn_2 = MaxPooling2D(pool_size=(3, 1), strides=3)(cnn_2)\n",
    "#     cnn_2 = Dropout(0.5)(cnn_2)\n",
    "\n",
    "#     #Block 3\n",
    "#     cnn_3 = Conv2D(100, (10,1), kernel_initializer=init)(cnn_2)\n",
    "#     cnn_3 = BatchNormalization()(cnn_3)\n",
    "#     cnn_3 = Activation(activation)(cnn_3)\n",
    "#     cnn_3 = MaxPooling2D(pool_size=(3, 1), strides=3)(cnn_3)\n",
    "#     cnn_3 = Dropout(0.5)(cnn_3)\n",
    "\n",
    "#     #Block 4\n",
    "#     cnn_4 = Conv2D(200, (10,1), kernel_initializer=init)(cnn_3)\n",
    "#     cnn_4 = BatchNormalization()(cnn_4)\n",
    "#     cnn_4 = Activation(activation)(cnn_4)\n",
    "#     cnn_4 = MaxPooling2D(pool_size=(3, 1), strides=3)(cnn_4)\n",
    "#     cnn_4 = Dropout(0.5)(cnn_4)\n",
    "    cnn_4 = Reshape((-1, 50*3))(inception_output_3)\n",
    "\n",
    "    #RNN Block\n",
    "    gru_1 = GRU(200,return_sequences=True,dropout=0.1)(cnn_4)\n",
    "    gru_2 = GRU(200,return_sequences=True,dropout=0.1)(gru_1)\n",
    "    gru_output_1 = keras.layers.concatenate([gru_1, gru_2], axis = 2)\n",
    "\n",
    "    gru_3 = GRU(200,return_sequences=True,dropout=0.1)(gru_output_1)\n",
    "    gru_output_2 = keras.layers.concatenate([gru_1, gru_2, gru_3], axis = 2)\n",
    "    gru_4 = GRU(200,dropout=0.1)(gru_output_2)\n",
    "    \n",
    "#     gru_1 = GRU(200,return_sequences=True,dropout=0.1)(cnn_4)\n",
    "#     gru_2 = GRU(200,return_sequences=True,dropout=0.1)(gru_1)\n",
    "#     gru_3 = GRU(200,return_sequences=True,dropout=0.1)(gru_2)\n",
    "#     gru_4 = GRU(200,dropout=0.1)(gru_3)\n",
    "    \n",
    "    out = Dense(units=4, kernel_initializer=init)(gru_4)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('softmax')(out)\n",
    "    model = Model(inputs = input_shape, outputs = out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: input_1\n",
      "(None, 1000, 22, 1)\n",
      "(None, 1000, 22, 1)\n",
      "\n",
      "Layer 2: conv2d_1\n",
      "<keras.initializers.VarianceScaling object at 0x000002A50C3C9F28>\n",
      "(None, 1000, 22, 1)\n",
      "(None, 200, 1, 50)\n",
      "\n",
      "Layer 3: conv2d_2\n",
      "<keras.initializers.VarianceScaling object at 0x000002A50C413B38>\n",
      "(None, 1000, 22, 1)\n",
      "(None, 200, 1, 50)\n",
      "\n",
      "Layer 4: conv2d_3\n",
      "<keras.initializers.VarianceScaling object at 0x000002A50F487FD0>\n",
      "(None, 1000, 22, 1)\n",
      "(None, 200, 1, 50)\n",
      "\n",
      "Layer 5: concatenate_1\n",
      "[(None, 200, 1, 50), (None, 200, 1, 50), (None, 200, 1, 50)]\n",
      "(None, 200, 1, 150)\n",
      "\n",
      "Layer 6: batch_normalization_1\n",
      "(None, 200, 1, 150)\n",
      "(None, 200, 1, 150)\n",
      "\n",
      "Layer 7: activation_1\n",
      "(None, 200, 1, 150)\n",
      "(None, 200, 1, 150)\n",
      "\n",
      "Layer 8: dropout_1\n",
      "(None, 200, 1, 150)\n",
      "(None, 200, 1, 150)\n",
      "\n",
      "Layer 9: conv2d_4\n",
      "<keras.initializers.VarianceScaling object at 0x000002A50F4AB898>\n",
      "(None, 200, 1, 150)\n",
      "(None, 40, 1, 50)\n",
      "\n",
      "Layer 10: conv2d_5\n",
      "<keras.initializers.VarianceScaling object at 0x000002A50F6AC400>\n",
      "(None, 200, 1, 150)\n",
      "(None, 40, 1, 50)\n",
      "\n",
      "Layer 11: conv2d_6\n",
      "<keras.initializers.VarianceScaling object at 0x000002A53A2E4DA0>\n",
      "(None, 200, 1, 150)\n",
      "(None, 40, 1, 50)\n",
      "\n",
      "Layer 12: concatenate_2\n",
      "[(None, 40, 1, 50), (None, 40, 1, 50), (None, 40, 1, 50)]\n",
      "(None, 40, 1, 150)\n",
      "\n",
      "Layer 13: batch_normalization_2\n",
      "(None, 40, 1, 150)\n",
      "(None, 40, 1, 150)\n",
      "\n",
      "Layer 14: activation_2\n",
      "(None, 40, 1, 150)\n",
      "(None, 40, 1, 150)\n",
      "\n",
      "Layer 15: dropout_2\n",
      "(None, 40, 1, 150)\n",
      "(None, 40, 1, 150)\n",
      "\n",
      "Layer 16: conv2d_7\n",
      "<keras.initializers.VarianceScaling object at 0x000002A53A320C50>\n",
      "(None, 40, 1, 150)\n",
      "(None, 8, 1, 50)\n",
      "\n",
      "Layer 17: conv2d_8\n",
      "<keras.initializers.VarianceScaling object at 0x000002A53A8CAFD0>\n",
      "(None, 40, 1, 150)\n",
      "(None, 8, 1, 50)\n",
      "\n",
      "Layer 18: conv2d_9\n",
      "<keras.initializers.VarianceScaling object at 0x000002A53A90FDA0>\n",
      "(None, 40, 1, 150)\n",
      "(None, 8, 1, 50)\n",
      "\n",
      "Layer 19: concatenate_3\n",
      "[(None, 8, 1, 50), (None, 8, 1, 50), (None, 8, 1, 50)]\n",
      "(None, 8, 1, 150)\n",
      "\n",
      "Layer 20: batch_normalization_3\n",
      "(None, 8, 1, 150)\n",
      "(None, 8, 1, 150)\n",
      "\n",
      "Layer 21: activation_3\n",
      "(None, 8, 1, 150)\n",
      "(None, 8, 1, 150)\n",
      "\n",
      "Layer 22: dropout_3\n",
      "(None, 8, 1, 150)\n",
      "(None, 8, 1, 150)\n",
      "\n",
      "Layer 23: reshape_1\n",
      "(None, 8, 1, 150)\n",
      "(None, 8, 150)\n",
      "\n",
      "Layer 24: gru_1\n",
      "<keras.initializers.VarianceScaling object at 0x000002A54807A5F8>\n",
      "(None, 8, 150)\n",
      "(None, 8, 200)\n",
      "\n",
      "Layer 25: gru_2\n",
      "<keras.initializers.VarianceScaling object at 0x000002A548097B38>\n",
      "(None, 8, 200)\n",
      "(None, 8, 200)\n",
      "\n",
      "Layer 26: concatenate_4\n",
      "[(None, 8, 200), (None, 8, 200)]\n",
      "(None, 8, 400)\n",
      "\n",
      "Layer 27: gru_3\n",
      "<keras.initializers.VarianceScaling object at 0x000002A50C3180B8>\n",
      "(None, 8, 400)\n",
      "(None, 8, 200)\n",
      "\n",
      "Layer 28: concatenate_5\n",
      "[(None, 8, 200), (None, 8, 200), (None, 8, 200)]\n",
      "(None, 8, 600)\n",
      "\n",
      "Layer 29: gru_4\n",
      "<keras.initializers.VarianceScaling object at 0x000002A548668E10>\n",
      "(None, 8, 600)\n",
      "(None, 200)\n",
      "\n",
      "Layer 30: dense_1\n",
      "<keras.initializers.VarianceScaling object at 0x000002A54872BD30>\n",
      "(None, 200)\n",
      "(None, 4)\n",
      "\n",
      "Layer 31: batch_normalization_4\n",
      "(None, 4)\n",
      "(None, 4)\n",
      "\n",
      "Layer 32: activation_4\n",
      "(None, 4)\n",
      "(None, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "model = create_rnn()\n",
    "for layers in model.layers:\n",
    "    print('Layer %d:' % i, layers.name)\n",
    "#     print(layers.__dict__)\n",
    "    if(hasattr(layers,'kernel_initializer')):\n",
    "        print(layers.kernel_initializer)\n",
    "    print(layers.input_shape)\n",
    "    print(layers.output_shape)\n",
    "    print()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1998 samples, validate on 282 samples\n",
      "Epoch 1/60\n",
      "1998/1998 [==============================] - 10s 5ms/step - loss: 1.4715 - acc: 0.2603 - val_loss: 1.3829 - val_acc: 0.2695\n",
      "Epoch 2/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.3737 - acc: 0.2918 - val_loss: 1.3922 - val_acc: 0.2695\n",
      "Epoch 3/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.3666 - acc: 0.3138 - val_loss: 1.3996 - val_acc: 0.2411\n",
      "Epoch 4/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.3500 - acc: 0.3338 - val_loss: 1.4060 - val_acc: 0.2979\n",
      "Epoch 5/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.3371 - acc: 0.3519 - val_loss: 1.3652 - val_acc: 0.3404\n",
      "Epoch 6/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.3350 - acc: 0.3579 - val_loss: 1.3723 - val_acc: 0.2943\n",
      "Epoch 7/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.2933 - acc: 0.3964 - val_loss: 1.3317 - val_acc: 0.4149\n",
      "Epoch 8/60\n",
      "1998/1998 [==============================] - 5s 2ms/step - loss: 1.2516 - acc: 0.4329 - val_loss: 1.3366 - val_acc: 0.3830\n",
      "Epoch 9/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.2028 - acc: 0.4605 - val_loss: 1.2771 - val_acc: 0.4078\n",
      "Epoch 10/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.1856 - acc: 0.4780 - val_loss: 1.3319 - val_acc: 0.4007\n",
      "Epoch 11/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.1473 - acc: 0.5010 - val_loss: 1.3955 - val_acc: 0.4326\n",
      "Epoch 12/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.1120 - acc: 0.5220 - val_loss: 1.2784 - val_acc: 0.4291\n",
      "Epoch 13/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.0881 - acc: 0.5365 - val_loss: 1.3080 - val_acc: 0.4362\n",
      "Epoch 14/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.0580 - acc: 0.5536 - val_loss: 1.2587 - val_acc: 0.4681\n",
      "Epoch 15/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.0263 - acc: 0.5626 - val_loss: 1.2743 - val_acc: 0.4610\n",
      "Epoch 16/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.9857 - acc: 0.5901 - val_loss: 1.3935 - val_acc: 0.4716\n",
      "Epoch 17/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.9771 - acc: 0.5986 - val_loss: 1.4518 - val_acc: 0.4184\n",
      "Epoch 18/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.9116 - acc: 0.6221 - val_loss: 1.3368 - val_acc: 0.4716\n",
      "Epoch 19/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.8888 - acc: 0.6411 - val_loss: 1.3327 - val_acc: 0.4823\n",
      "Epoch 20/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.8710 - acc: 0.6507 - val_loss: 1.3187 - val_acc: 0.4823\n",
      "Epoch 21/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.8323 - acc: 0.6762 - val_loss: 1.3397 - val_acc: 0.4716\n",
      "Epoch 22/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.7895 - acc: 0.6977 - val_loss: 1.4120 - val_acc: 0.4681\n",
      "Epoch 23/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.7864 - acc: 0.7007 - val_loss: 1.3673 - val_acc: 0.4539\n",
      "Epoch 24/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.7742 - acc: 0.7047 - val_loss: 1.4067 - val_acc: 0.4539\n",
      "Epoch 25/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.7336 - acc: 0.7112 - val_loss: 1.3660 - val_acc: 0.4752\n",
      "Epoch 26/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.7195 - acc: 0.7327 - val_loss: 1.3108 - val_acc: 0.4858\n",
      "Epoch 27/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.6844 - acc: 0.7432 - val_loss: 1.4726 - val_acc: 0.4574\n",
      "Epoch 28/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.6481 - acc: 0.7608 - val_loss: 1.5053 - val_acc: 0.4716\n",
      "Epoch 29/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.6207 - acc: 0.7808 - val_loss: 1.5100 - val_acc: 0.4716\n",
      "Epoch 30/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.6044 - acc: 0.7653 - val_loss: 1.4962 - val_acc: 0.4539\n",
      "Epoch 31/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.5892 - acc: 0.7993 - val_loss: 1.5006 - val_acc: 0.4752\n",
      "Epoch 32/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.5884 - acc: 0.7878 - val_loss: 1.4935 - val_acc: 0.4716\n",
      "Epoch 33/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.5441 - acc: 0.8008 - val_loss: 1.6137 - val_acc: 0.4610\n",
      "Epoch 34/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.5498 - acc: 0.8143 - val_loss: 1.6521 - val_acc: 0.4574\n",
      "Epoch 35/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.5200 - acc: 0.8123 - val_loss: 1.6615 - val_acc: 0.4504\n",
      "Epoch 36/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.5226 - acc: 0.8183 - val_loss: 1.5804 - val_acc: 0.4681\n",
      "Epoch 37/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4846 - acc: 0.8373 - val_loss: 1.5491 - val_acc: 0.4894\n",
      "Epoch 38/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4705 - acc: 0.8373 - val_loss: 1.5501 - val_acc: 0.5035\n",
      "Epoch 39/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4610 - acc: 0.8428 - val_loss: 1.5566 - val_acc: 0.4752\n",
      "Epoch 40/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4429 - acc: 0.8519 - val_loss: 1.6515 - val_acc: 0.4681\n",
      "Epoch 41/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4190 - acc: 0.8669 - val_loss: 1.6256 - val_acc: 0.4716\n",
      "Epoch 42/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4314 - acc: 0.8519 - val_loss: 1.6460 - val_acc: 0.4539\n",
      "Epoch 43/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4094 - acc: 0.8649 - val_loss: 1.7014 - val_acc: 0.4787\n",
      "Epoch 44/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4095 - acc: 0.8564 - val_loss: 1.7223 - val_acc: 0.4823\n",
      "Epoch 45/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4029 - acc: 0.8629 - val_loss: 1.6970 - val_acc: 0.4716\n",
      "Epoch 46/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3824 - acc: 0.8774 - val_loss: 1.7251 - val_acc: 0.4752\n",
      "Epoch 47/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3887 - acc: 0.8704 - val_loss: 1.6967 - val_acc: 0.4681\n",
      "Epoch 48/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3780 - acc: 0.8729 - val_loss: 1.6735 - val_acc: 0.4787\n",
      "Epoch 49/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3742 - acc: 0.8829 - val_loss: 1.7099 - val_acc: 0.4929\n",
      "Epoch 50/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4105 - acc: 0.8539 - val_loss: 1.7317 - val_acc: 0.4539\n",
      "Epoch 51/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3701 - acc: 0.8714 - val_loss: 1.7325 - val_acc: 0.4787\n",
      "Epoch 52/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3389 - acc: 0.8894 - val_loss: 1.7945 - val_acc: 0.4752\n",
      "Epoch 53/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3184 - acc: 0.9029 - val_loss: 1.8039 - val_acc: 0.4504\n",
      "Epoch 54/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3062 - acc: 0.8949 - val_loss: 1.8019 - val_acc: 0.4716\n",
      "Epoch 55/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3112 - acc: 0.9069 - val_loss: 1.8783 - val_acc: 0.4681\n",
      "Epoch 56/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.2987 - acc: 0.9059 - val_loss: 1.8648 - val_acc: 0.4894\n",
      "Epoch 57/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3196 - acc: 0.8969 - val_loss: 1.7403 - val_acc: 0.4929\n",
      "Epoch 58/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3072 - acc: 0.9014 - val_loss: 1.8502 - val_acc: 0.4823\n",
      "Epoch 59/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3053 - acc: 0.8994 - val_loss: 1.7289 - val_acc: 0.5106\n",
      "Epoch 60/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.2911 - acc: 0.9019 - val_loss: 1.8836 - val_acc: 0.4539\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a70e1b1588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training\n",
    "batch_size = 16\n",
    "epochs = 60\n",
    "opt = keras.optimizers.adam(lr=0.001)\n",
    "results = []\n",
    "\n",
    "model = create_rnn()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=opt,\n",
    "             metrics=['accuracy'])\n",
    "result = model.fit(X_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   validation_data=(X_val, y_val),\n",
    "                   epochs=epochs)\n",
    "results.append(result.history['val_acc'])\n",
    "\n",
    "plt.plot(result.history['acc'])\n",
    "plt.plot(result.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.902\n",
      "Validation Accuracy: 0.454\n",
      "Testing Accuracy: 0.392\n"
     ]
    }
   ],
   "source": [
    "# Testing Accuracy\n",
    "test_results = model.predict(x=X_test, batch_size=batch_size)\n",
    "categ_results = np.argmax(test_results,axis=1)\n",
    "categ_test = np.argmax(y_test,axis=1)\n",
    "test_acc = np.sum(categ_results==categ_test)/len(categ_results)\n",
    "print('Training Accuracy: %.3f' % result.history['acc'][-1])\n",
    "print('Validation Accuracy: %.3f' % result.history['val_acc'][-1])\n",
    "print('Testing Accuracy: %.3f' % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
