{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Utilities\\Anaconda3\\envs\\keras\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Keras Package\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, Flatten, LSTM, Embedding, Reshape, GRU, Input, RNN\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "#Numpy\n",
    "import numpy as np\n",
    "#Load Data\n",
    "import h5py, glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "#Timing\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "def import_data(filename):\n",
    "    #Removes nan trial from imported data\n",
    "    def remove_nan(X):\n",
    "        idx = 0\n",
    "        idx_nan = []\n",
    "        for trial in X:\n",
    "            if (np.isnan(trial).any()):\n",
    "                print('Trial %d has nan' % idx)\n",
    "                idx_nan.append(idx)\n",
    "            idx += 1\n",
    "        return np.delete(X,idx_nan,0), np.delete(y,idx_nan,0)\n",
    "\n",
    "    #Load data\n",
    "    A01T = h5py.File(filename, 'r')\n",
    "    X = np.copy(A01T['image'])\n",
    "    X = X[:,0:22,:] #remove EOG lines\n",
    "\n",
    "    #769-left hand; 770-right hand; 771-both feet; 772-tongue\n",
    "    y = np.copy(A01T['type'])\n",
    "    y = y[0,0:X.shape[0]:1]\n",
    "    y = np.asarray(y, dtype=np.int32)\n",
    "    \n",
    "    #Data Preprocess\n",
    "    X, y = remove_nan(X) #Remove nans\n",
    "    X = np.transpose(X,(0,2,1))\n",
    "    X = np.expand_dims(X,3) #Expand dimension\n",
    "\n",
    "    #Convert y to one-hot label\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    encoded_y = encoder.transform(y)\n",
    "    y = np_utils.to_categorical(encoded_y)\n",
    "    num_classes = y.shape[1]\n",
    "\n",
    "    #Check whole dimensions\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    return X, y, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Trial 56 has nan\n",
      "(287, 1000, 22, 1)\n",
      "(287, 4)\n",
      "1\n",
      "Trial 237 has nan\n",
      "Trial 284 has nan\n",
      "(286, 1000, 22, 1)\n",
      "(286, 4)\n",
      "2\n",
      "Trial 113 has nan\n",
      "Trial 249 has nan\n",
      "(286, 1000, 22, 1)\n",
      "(286, 4)\n",
      "3\n",
      "Trial 144 has nan\n",
      "Trial 145 has nan\n",
      "Trial 146 has nan\n",
      "Trial 179 has nan\n",
      "(284, 1000, 22, 1)\n",
      "(284, 4)\n",
      "4\n",
      "Trial 6 has nan\n",
      "Trial 28 has nan\n",
      "Trial 57 has nan\n",
      "Trial 101 has nan\n",
      "Trial 220 has nan\n",
      "Trial 225 has nan\n",
      "(282, 1000, 22, 1)\n",
      "(282, 4)\n",
      "5\n",
      "Trial 97 has nan\n",
      "Trial 115 has nan\n",
      "Trial 140 has nan\n",
      "(285, 1000, 22, 1)\n",
      "(285, 4)\n",
      "6\n",
      "(288, 1000, 22, 1)\n",
      "(288, 4)\n",
      "7\n",
      "Trial 58 has nan\n",
      "Trial 81 has nan\n",
      "Trial 124 has nan\n",
      "Trial 151 has nan\n",
      "Trial 178 has nan\n",
      "Trial 275 has nan\n",
      "(282, 1000, 22, 1)\n",
      "(282, 4)\n",
      "8\n",
      "Trial 22 has nan\n",
      "Trial 61 has nan\n",
      "Trial 92 has nan\n",
      "Trial 93 has nan\n",
      "Trial 159 has nan\n",
      "Trial 202 has nan\n",
      "Trial 204 has nan\n",
      "Trial 218 has nan\n",
      "Trial 239 has nan\n",
      "Trial 250 has nan\n",
      "(278, 1000, 22, 1)\n",
      "(278, 4)\n"
     ]
    }
   ],
   "source": [
    "#Load files\n",
    "files = glob.glob('project_datasets/*.mat')\n",
    "subjects = -1\n",
    "X = {}\n",
    "y = {}\n",
    "for file in files:\n",
    "    subjects += 1\n",
    "    print(subjects)\n",
    "    X[str(subjects)], y[str(subjects)], num_classes = import_data(file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Concatenate all data (for v2_bulk)\n",
    "# t0 = time()\n",
    "# X_net = X[str(0)];\n",
    "# y_net = y[str(0)];\n",
    "# for i in np.arange(1,len(X)):\n",
    "#     X_net = np.concatenate((X_net,X[str(i)]),axis=0)\n",
    "#     y_net = np.concatenate((y_net,y[str(i)]),axis=0)\n",
    "# t1 = time()\n",
    "# total = t1 - t0\n",
    "# print(\"Time to concatenate = %f\" % total)\n",
    "# print()\n",
    "\n",
    "#Creating Validation and Testing data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_net, y_net, test_size = 5/100, random_state=0)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 5/95, random_state=0)\n",
    "# print(X_net.shape)\n",
    "# print(X_train.shape)\n",
    "# print(X_val.shape)\n",
    "# print(X_test.shape)\n",
    "# print()\n",
    "# print(y_net.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_val.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1998, 1000, 22, 1)\n",
      "(282, 1000, 22, 1)\n",
      "(278, 1000, 22, 1)\n",
      "\n",
      "(1998, 4)\n",
      "(282, 4)\n",
      "(278, 4)\n"
     ]
    }
   ],
   "source": [
    "# #Concatenate all data (for v1_bulk)\n",
    "idx = np.arange(len(X))\n",
    "idx_train = idx[0:-2]\n",
    "idx_val = idx[-2]\n",
    "idx_test = idx[-1]\n",
    "X_train, y_train = X[str(idx_train[0])], y[str(idx_train[0])]\n",
    "X_val, y_val = X[str(idx_val)], y[str(idx_val)]\n",
    "X_test, y_test = X[str(idx_test)], y[str(idx_test)]\n",
    "for i in idx_train[1:]:\n",
    "    X_train = np.concatenate((X_train,X[str(i)]),axis=0)\n",
    "    y_train = np.concatenate((y_train,y[str(i)]),axis=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print()\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Deep CNN\n",
    "# Conv2D: (layer name, filter length, number of filters, stride size)\n",
    "# GRU layers: (layer name, number of filters)\n",
    "def create_rnn():\n",
    "    activation = 'elu'\n",
    "    input_shape = Input(shape = X['1'][0].shape)\n",
    "    init = 'glorot_uniform'\n",
    "\n",
    "    #Block 1\n",
    "#     cnn_1 = Conv2D(25, (10,1), kernel_initializer=init)(input_shape)\n",
    "#     cnn_1 = Conv2D(25, (1,22), kernel_initializer=init)(cnn_1)\n",
    "#     cnn_1 = BatchNormalization()(cnn_1)\n",
    "#     cnn_1 = Activation(activation)(cnn_1)\n",
    "#     cnn_1 = MaxPooling2D(pool_size=(3, 1), strides=3)(cnn_1)\n",
    "#     cnn_1 = Dropout(0.5)(cnn_1)\n",
    "    \n",
    "    #Inception 1\n",
    "    tower_11 = Conv2D(50, (5,22), strides=(5,22), padding='same', kernel_initializer=init)(input_shape)\n",
    "    tower_12 = Conv2D(50, (10,22), strides=(5,22), padding='same', kernel_initializer=init)(input_shape)\n",
    "    tower_13 = Conv2D(50, (20,22), strides=(5,22), padding='same', kernel_initializer=init)(input_shape)\n",
    "    inception_output_1 = keras.layers.concatenate([tower_11, tower_12, tower_13], axis = 3)\n",
    "    inception_output_1 = BatchNormalization()(inception_output_1)\n",
    "    inception_output_1 = Activation(activation)(inception_output_1)\n",
    "    inception_output_1 = Dropout(0.5)(inception_output_1)\n",
    "    \n",
    "    #Inception 2\n",
    "    tower_21 = Conv2D(50, (5,1), strides=5, padding='same', kernel_initializer=init)(inception_output_1)\n",
    "    tower_22 = Conv2D(50, (10,1), strides=5, padding='same', kernel_initializer=init)(inception_output_1)\n",
    "    tower_23 = Conv2D(50, (20,1), strides=5, padding='same', kernel_initializer=init)(inception_output_1)\n",
    "    inception_output_2 = keras.layers.concatenate([tower_21, tower_22, tower_23], axis = 3)\n",
    "    inception_output_2 = BatchNormalization()(inception_output_2)\n",
    "    inception_output_2 = Activation(activation)(inception_output_2)\n",
    "    inception_output_2 = Dropout(0.5)(inception_output_2)\n",
    "    \n",
    "    #Inception 3\n",
    "    tower_31 = Conv2D(50, (5,1), strides=5, padding='same', kernel_initializer=init)(inception_output_2)\n",
    "    tower_32 = Conv2D(50, (10,1), strides=5, padding='same', kernel_initializer=init)(inception_output_2)\n",
    "    tower_33 = Conv2D(50, (20,1), strides=5, padding='same', kernel_initializer=init)(inception_output_2)\n",
    "    inception_output_3 = keras.layers.concatenate([tower_31, tower_32, tower_33], axis = 3)\n",
    "    inception_output_3 = BatchNormalization()(inception_output_3)\n",
    "    inception_output_3 = Activation(activation)(inception_output_3)\n",
    "    inception_output_3 = Dropout(0.5)(inception_output_3)\n",
    "\n",
    "#     #Block 2\n",
    "#     cnn_2 = Conv2D(50, (10,1), kernel_initializer=init)(cnn_1)\n",
    "#     cnn_2 = BatchNormalization()(cnn_2)\n",
    "#     cnn_2 = Activation(activation)(cnn_2)\n",
    "#     cnn_2 = MaxPooling2D(pool_size=(3, 1), strides=3)(cnn_2)\n",
    "#     cnn_2 = Dropout(0.5)(cnn_2)\n",
    "\n",
    "#     #Block 3\n",
    "#     cnn_3 = Conv2D(100, (10,1), kernel_initializer=init)(cnn_2)\n",
    "#     cnn_3 = BatchNormalization()(cnn_3)\n",
    "#     cnn_3 = Activation(activation)(cnn_3)\n",
    "#     cnn_3 = MaxPooling2D(pool_size=(3, 1), strides=3)(cnn_3)\n",
    "#     cnn_3 = Dropout(0.5)(cnn_3)\n",
    "\n",
    "#     #Block 4\n",
    "#     cnn_4 = Conv2D(200, (10,1), kernel_initializer=init)(cnn_3)\n",
    "#     cnn_4 = BatchNormalization()(cnn_4)\n",
    "#     cnn_4 = Activation(activation)(cnn_4)\n",
    "#     cnn_4 = MaxPooling2D(pool_size=(3, 1), strides=3)(cnn_4)\n",
    "#     cnn_4 = Dropout(0.5)(cnn_4)\n",
    "    cnn_4 = Reshape((-1, 50*3))(inception_output_3)\n",
    "\n",
    "    #RNN Block\n",
    "#     gru_1 = GRU(200,return_sequences=True,dropout=0.1)(cnn_4)\n",
    "#     gru_2 = GRU(200,return_sequences=True,dropout=0.1)(gru_1)\n",
    "#     gru_output_1 = keras.layers.concatenate([gru_1, gru_2], axis = 2)\n",
    "\n",
    "#     gru_3 = GRU(200,return_sequences=True,dropout=0.1)(gru_output_1)\n",
    "#     gru_output_2 = keras.layers.concatenate([gru_1, gru_2, gru_3], axis = 2)\n",
    "#     gru_4 = GRU(200,dropout=0.1)(gru_output_2)\n",
    "    \n",
    "    gru_1 = GRU(200,return_sequences=True,dropout=0.1)(cnn_4)\n",
    "    gru_2 = GRU(200,return_sequences=True,dropout=0.1)(gru_1)\n",
    "    gru_3 = GRU(200,return_sequences=True,dropout=0.1)(gru_2)\n",
    "    gru_4 = GRU(200,dropout=0.1)(gru_3)\n",
    "    \n",
    "    out = Dense(units=4, kernel_initializer=init)(gru_4)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('softmax')(out)\n",
    "    model = Model(inputs = input_shape, outputs = out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: input_1\n",
      "(None, 1000, 22, 1)\n",
      "(None, 1000, 22, 1)\n",
      "\n",
      "Layer 2: conv2d_1\n",
      "<keras.initializers.VarianceScaling object at 0x0000020415F663C8>\n",
      "(None, 1000, 22, 1)\n",
      "(None, 200, 1, 50)\n",
      "\n",
      "Layer 3: conv2d_2\n",
      "<keras.initializers.VarianceScaling object at 0x0000020418FCAD30>\n",
      "(None, 1000, 22, 1)\n",
      "(None, 200, 1, 50)\n",
      "\n",
      "Layer 4: conv2d_3\n",
      "<keras.initializers.VarianceScaling object at 0x0000020419017EB8>\n",
      "(None, 1000, 22, 1)\n",
      "(None, 200, 1, 50)\n",
      "\n",
      "Layer 5: concatenate_1\n",
      "[(None, 200, 1, 50), (None, 200, 1, 50), (None, 200, 1, 50)]\n",
      "(None, 200, 1, 150)\n",
      "\n",
      "Layer 6: batch_normalization_1\n",
      "(None, 200, 1, 150)\n",
      "(None, 200, 1, 150)\n",
      "\n",
      "Layer 7: activation_1\n",
      "(None, 200, 1, 150)\n",
      "(None, 200, 1, 150)\n",
      "\n",
      "Layer 8: dropout_1\n",
      "(None, 200, 1, 150)\n",
      "(None, 200, 1, 150)\n",
      "\n",
      "Layer 9: conv2d_4\n",
      "<keras.initializers.VarianceScaling object at 0x000002041903B780>\n",
      "(None, 200, 1, 150)\n",
      "(None, 40, 1, 50)\n",
      "\n",
      "Layer 10: conv2d_5\n",
      "<keras.initializers.VarianceScaling object at 0x0000020443EA1940>\n",
      "(None, 200, 1, 150)\n",
      "(None, 40, 1, 50)\n",
      "\n",
      "Layer 11: conv2d_6\n",
      "<keras.initializers.VarianceScaling object at 0x0000020443F075F8>\n",
      "(None, 200, 1, 150)\n",
      "(None, 40, 1, 50)\n",
      "\n",
      "Layer 12: concatenate_2\n",
      "[(None, 40, 1, 50), (None, 40, 1, 50), (None, 40, 1, 50)]\n",
      "(None, 40, 1, 150)\n",
      "\n",
      "Layer 13: batch_normalization_2\n",
      "(None, 40, 1, 150)\n",
      "(None, 40, 1, 150)\n",
      "\n",
      "Layer 14: activation_2\n",
      "(None, 40, 1, 150)\n",
      "(None, 40, 1, 150)\n",
      "\n",
      "Layer 15: dropout_2\n",
      "(None, 40, 1, 150)\n",
      "(None, 40, 1, 150)\n",
      "\n",
      "Layer 16: conv2d_7\n",
      "<keras.initializers.VarianceScaling object at 0x0000020443F346A0>\n",
      "(None, 40, 1, 150)\n",
      "(None, 8, 1, 50)\n",
      "\n",
      "Layer 17: conv2d_8\n",
      "<keras.initializers.VarianceScaling object at 0x0000020443F589B0>\n",
      "(None, 40, 1, 150)\n",
      "(None, 8, 1, 50)\n",
      "\n",
      "Layer 18: conv2d_9\n",
      "<keras.initializers.VarianceScaling object at 0x000002044A4E3CC0>\n",
      "(None, 40, 1, 150)\n",
      "(None, 8, 1, 50)\n",
      "\n",
      "Layer 19: concatenate_3\n",
      "[(None, 8, 1, 50), (None, 8, 1, 50), (None, 8, 1, 50)]\n",
      "(None, 8, 1, 150)\n",
      "\n",
      "Layer 20: batch_normalization_3\n",
      "(None, 8, 1, 150)\n",
      "(None, 8, 1, 150)\n",
      "\n",
      "Layer 21: activation_3\n",
      "(None, 8, 1, 150)\n",
      "(None, 8, 1, 150)\n",
      "\n",
      "Layer 22: dropout_3\n",
      "(None, 8, 1, 150)\n",
      "(None, 8, 1, 150)\n",
      "\n",
      "Layer 23: reshape_1\n",
      "(None, 8, 1, 150)\n",
      "(None, 8, 150)\n",
      "\n",
      "Layer 24: gru_1\n",
      "<keras.initializers.VarianceScaling object at 0x000002044ABA5FD0>\n",
      "(None, 8, 150)\n",
      "(None, 8, 200)\n",
      "\n",
      "Layer 25: gru_2\n",
      "<keras.initializers.VarianceScaling object at 0x000002044ABC7EF0>\n",
      "(None, 8, 200)\n",
      "(None, 8, 200)\n",
      "\n",
      "Layer 26: gru_3\n",
      "<keras.initializers.VarianceScaling object at 0x00000204791CDC50>\n",
      "(None, 8, 200)\n",
      "(None, 8, 200)\n",
      "\n",
      "Layer 27: gru_4\n",
      "<keras.initializers.VarianceScaling object at 0x0000020479397DD8>\n",
      "(None, 8, 200)\n",
      "(None, 200)\n",
      "\n",
      "Layer 28: dense_1\n",
      "<keras.initializers.VarianceScaling object at 0x0000020479781B70>\n",
      "(None, 200)\n",
      "(None, 4)\n",
      "\n",
      "Layer 29: batch_normalization_4\n",
      "(None, 4)\n",
      "(None, 4)\n",
      "\n",
      "Layer 30: activation_4\n",
      "(None, 4)\n",
      "(None, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "model = create_rnn()\n",
    "for layers in model.layers:\n",
    "    print('Layer %d:' % i, layers.name)\n",
    "#     print(layers.__dict__)\n",
    "    if(hasattr(layers,'kernel_initializer')):\n",
    "        print(layers.kernel_initializer)\n",
    "    print(layers.input_shape)\n",
    "    print(layers.output_shape)\n",
    "    print()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1998 samples, validate on 282 samples\n",
      "Epoch 1/60\n",
      "1998/1998 [==============================] - 10s 5ms/step - loss: 1.4328 - acc: 0.2678 - val_loss: 1.3770 - val_acc: 0.3156\n",
      "Epoch 2/60\n",
      "1998/1998 [==============================] - 5s 2ms/step - loss: 1.3715 - acc: 0.3053 - val_loss: 1.3828 - val_acc: 0.3227\n",
      "Epoch 3/60\n",
      "1998/1998 [==============================] - 5s 2ms/step - loss: 1.3620 - acc: 0.3193 - val_loss: 1.3449 - val_acc: 0.3121\n",
      "Epoch 4/60\n",
      "1998/1998 [==============================] - 5s 2ms/step - loss: 1.3416 - acc: 0.3549 - val_loss: 1.3788 - val_acc: 0.2979\n",
      "Epoch 5/60\n",
      "1998/1998 [==============================] - 5s 2ms/step - loss: 1.3233 - acc: 0.3519 - val_loss: 1.3801 - val_acc: 0.3546\n",
      "Epoch 6/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.2708 - acc: 0.4114 - val_loss: 1.3193 - val_acc: 0.3972\n",
      "Epoch 7/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.2560 - acc: 0.4184 - val_loss: 1.3627 - val_acc: 0.3440\n",
      "Epoch 8/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.2377 - acc: 0.4439 - val_loss: 1.2940 - val_acc: 0.4184\n",
      "Epoch 9/60\n",
      "1998/1998 [==============================] - 5s 2ms/step - loss: 1.1987 - acc: 0.4695 - val_loss: 1.2769 - val_acc: 0.4184\n",
      "Epoch 10/60\n",
      "1998/1998 [==============================] - 5s 2ms/step - loss: 1.1687 - acc: 0.4815 - val_loss: 1.3787 - val_acc: 0.4078\n",
      "Epoch 11/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.1209 - acc: 0.5055 - val_loss: 1.3547 - val_acc: 0.4610\n",
      "Epoch 12/60\n",
      "1998/1998 [==============================] - 5s 2ms/step - loss: 1.0988 - acc: 0.5175 - val_loss: 1.3537 - val_acc: 0.4468\n",
      "Epoch 13/60\n",
      "1998/1998 [==============================] - 5s 2ms/step - loss: 1.0887 - acc: 0.5315 - val_loss: 1.4431 - val_acc: 0.3759\n",
      "Epoch 14/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.0582 - acc: 0.5395 - val_loss: 1.3398 - val_acc: 0.4362\n",
      "Epoch 15/60\n",
      "1998/1998 [==============================] - 5s 2ms/step - loss: 1.0408 - acc: 0.5526 - val_loss: 1.3586 - val_acc: 0.4397\n",
      "Epoch 16/60\n",
      "1998/1998 [==============================] - 5s 2ms/step - loss: 1.0022 - acc: 0.5791 - val_loss: 1.4345 - val_acc: 0.4078\n",
      "Epoch 17/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 1.0018 - acc: 0.5726 - val_loss: 1.3658 - val_acc: 0.4113\n",
      "Epoch 18/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.9576 - acc: 0.5846 - val_loss: 1.3893 - val_acc: 0.3865\n",
      "Epoch 19/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.9458 - acc: 0.6001 - val_loss: 1.4698 - val_acc: 0.4043\n",
      "Epoch 20/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.9420 - acc: 0.6291 - val_loss: 1.4074 - val_acc: 0.3759\n",
      "Epoch 21/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.9140 - acc: 0.6301 - val_loss: 1.5326 - val_acc: 0.3865\n",
      "Epoch 22/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.8464 - acc: 0.6657 - val_loss: 1.5593 - val_acc: 0.3652\n",
      "Epoch 23/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.8590 - acc: 0.6567 - val_loss: 1.4212 - val_acc: 0.4078\n",
      "Epoch 24/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.8415 - acc: 0.6702 - val_loss: 1.4612 - val_acc: 0.4078\n",
      "Epoch 25/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.8209 - acc: 0.6817 - val_loss: 1.6281 - val_acc: 0.3688\n",
      "Epoch 26/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.7766 - acc: 0.6972 - val_loss: 1.4944 - val_acc: 0.3723\n",
      "Epoch 27/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.7576 - acc: 0.7167 - val_loss: 1.5051 - val_acc: 0.4113\n",
      "Epoch 28/60\n",
      "1998/1998 [==============================] - 6s 3ms/step - loss: 0.7203 - acc: 0.7362 - val_loss: 1.5300 - val_acc: 0.4149\n",
      "Epoch 29/60\n",
      "1998/1998 [==============================] - 6s 3ms/step - loss: 0.7184 - acc: 0.7302 - val_loss: 1.4816 - val_acc: 0.4397\n",
      "Epoch 30/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.7288 - acc: 0.7327 - val_loss: 1.5410 - val_acc: 0.4007\n",
      "Epoch 31/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.6910 - acc: 0.7467 - val_loss: 1.6244 - val_acc: 0.3936\n",
      "Epoch 32/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.6536 - acc: 0.7613 - val_loss: 1.6055 - val_acc: 0.4291\n",
      "Epoch 33/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.6342 - acc: 0.7688 - val_loss: 1.6532 - val_acc: 0.3901\n",
      "Epoch 34/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.6064 - acc: 0.7848 - val_loss: 1.6190 - val_acc: 0.4007\n",
      "Epoch 35/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.6159 - acc: 0.7873 - val_loss: 1.5471 - val_acc: 0.4397\n",
      "Epoch 36/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.5976 - acc: 0.7898 - val_loss: 1.5912 - val_acc: 0.4184\n",
      "Epoch 37/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.6211 - acc: 0.7723 - val_loss: 1.5806 - val_acc: 0.4255\n",
      "Epoch 38/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.5740 - acc: 0.7953 - val_loss: 1.6871 - val_acc: 0.4113\n",
      "Epoch 39/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.5358 - acc: 0.8108 - val_loss: 1.9185 - val_acc: 0.3723\n",
      "Epoch 40/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.5614 - acc: 0.8008 - val_loss: 1.7542 - val_acc: 0.3759\n",
      "Epoch 41/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.5376 - acc: 0.8033 - val_loss: 1.7557 - val_acc: 0.4220\n",
      "Epoch 42/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.5227 - acc: 0.8118 - val_loss: 1.6399 - val_acc: 0.4397\n",
      "Epoch 43/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.5471 - acc: 0.8053 - val_loss: 1.7191 - val_acc: 0.4113\n",
      "Epoch 44/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.5037 - acc: 0.8238 - val_loss: 1.7515 - val_acc: 0.4433\n",
      "Epoch 45/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4889 - acc: 0.8218 - val_loss: 1.7219 - val_acc: 0.4362\n",
      "Epoch 46/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4782 - acc: 0.8298 - val_loss: 1.8367 - val_acc: 0.3830\n",
      "Epoch 47/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4502 - acc: 0.8468 - val_loss: 1.8236 - val_acc: 0.4326\n",
      "Epoch 48/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4454 - acc: 0.8504 - val_loss: 1.7965 - val_acc: 0.4255\n",
      "Epoch 49/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4606 - acc: 0.8428 - val_loss: 1.9078 - val_acc: 0.4184\n",
      "Epoch 50/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4545 - acc: 0.8433 - val_loss: 1.7646 - val_acc: 0.4078\n",
      "Epoch 51/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4357 - acc: 0.8549 - val_loss: 1.7457 - val_acc: 0.4539\n",
      "Epoch 52/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4241 - acc: 0.8539 - val_loss: 1.7254 - val_acc: 0.4574\n",
      "Epoch 53/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3940 - acc: 0.8564 - val_loss: 1.7648 - val_acc: 0.4539\n",
      "Epoch 54/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3852 - acc: 0.8759 - val_loss: 1.8526 - val_acc: 0.4362\n",
      "Epoch 55/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4034 - acc: 0.8554 - val_loss: 1.7435 - val_acc: 0.4397\n",
      "Epoch 56/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.4204 - acc: 0.8624 - val_loss: 1.8721 - val_acc: 0.4291\n",
      "Epoch 57/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3647 - acc: 0.8779 - val_loss: 2.0466 - val_acc: 0.4007\n",
      "Epoch 58/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3872 - acc: 0.8734 - val_loss: 1.9151 - val_acc: 0.4043\n",
      "Epoch 59/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3710 - acc: 0.8814 - val_loss: 1.9371 - val_acc: 0.4113\n",
      "Epoch 60/60\n",
      "1998/1998 [==============================] - 5s 3ms/step - loss: 0.3262 - acc: 0.8949 - val_loss: 2.0553 - val_acc: 0.4184\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2060e1c4d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training\n",
    "batch_size = 16\n",
    "epochs = 60\n",
    "opt = keras.optimizers.adam(lr=0.001)\n",
    "results = []\n",
    "\n",
    "model = create_rnn()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=opt,\n",
    "             metrics=['accuracy'])\n",
    "result = model.fit(X_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   validation_data=(X_val, y_val),\n",
    "                   epochs=epochs)\n",
    "results.append(result.history['val_acc'])\n",
    "\n",
    "plt.plot(result.history['acc'])\n",
    "plt.plot(result.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.895\n",
      "Validation Accuracy: 0.418\n",
      "Testing Accuracy: 0.450\n"
     ]
    }
   ],
   "source": [
    "# Testing Accuracy\n",
    "test_results = model.predict(x=X_test, batch_size=batch_size)\n",
    "categ_results = np.argmax(test_results,axis=1)\n",
    "categ_test = np.argmax(y_test,axis=1)\n",
    "test_acc = np.sum(categ_results==categ_test)/len(categ_results)\n",
    "print('Training Accuracy: %.3f' % result.history['acc'][-1])\n",
    "print('Validation Accuracy: %.3f' % result.history['val_acc'][-1])\n",
    "print('Testing Accuracy: %.3f' % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
